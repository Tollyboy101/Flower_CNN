{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1277 samples, validate on 226 samples\n",
      "Epoch 1/20\n",
      "1277/1277 [==============================] - 23s 18ms/step - loss: 0.6309 - acc: 0.6648 - val_loss: 0.5561 - val_acc: 0.7743\n",
      "Epoch 2/20\n",
      "1277/1277 [==============================] - 24s 18ms/step - loss: 0.5513 - acc: 0.7197 - val_loss: 0.5685 - val_acc: 0.6903\n",
      "Epoch 3/20\n",
      "1277/1277 [==============================] - 23s 18ms/step - loss: 0.5255 - acc: 0.7392 - val_loss: 0.6236 - val_acc: 0.6416\n",
      "Epoch 4/20\n",
      "1277/1277 [==============================] - 23s 18ms/step - loss: 0.5110 - acc: 0.7353 - val_loss: 0.5778 - val_acc: 0.6903\n",
      "Epoch 5/20\n",
      "1277/1277 [==============================] - 22s 17ms/step - loss: 0.4647 - acc: 0.7894 - val_loss: 0.5622 - val_acc: 0.6681\n",
      "Epoch 6/20\n",
      "1277/1277 [==============================] - 22s 17ms/step - loss: 0.4358 - acc: 0.7964 - val_loss: 0.6895 - val_acc: 0.6239\n",
      "Epoch 7/20\n",
      "1277/1277 [==============================] - 22s 17ms/step - loss: 0.3934 - acc: 0.8191 - val_loss: 0.6570 - val_acc: 0.6372\n",
      "Epoch 8/20\n",
      "1277/1277 [==============================] - 23s 18ms/step - loss: 0.3404 - acc: 0.8520 - val_loss: 0.6324 - val_acc: 0.6416\n",
      "Epoch 9/20\n",
      "1277/1277 [==============================] - 21s 16ms/step - loss: 0.3080 - acc: 0.8661 - val_loss: 0.6412 - val_acc: 0.6549\n",
      "Epoch 10/20\n",
      "1277/1277 [==============================] - 24s 19ms/step - loss: 0.2622 - acc: 0.8904 - val_loss: 0.7695 - val_acc: 0.6460\n",
      "Epoch 11/20\n",
      "1277/1277 [==============================] - 21s 16ms/step - loss: 0.2121 - acc: 0.9146 - val_loss: 0.6559 - val_acc: 0.6947\n",
      "Epoch 12/20\n",
      "1277/1277 [==============================] - 21s 16ms/step - loss: 0.2047 - acc: 0.9123 - val_loss: 0.6628 - val_acc: 0.7035\n",
      "Epoch 13/20\n",
      "1277/1277 [==============================] - 21s 16ms/step - loss: 0.1726 - acc: 0.9334 - val_loss: 0.8189 - val_acc: 0.6150\n",
      "Epoch 14/20\n",
      "1277/1277 [==============================] - 21s 17ms/step - loss: 0.1762 - acc: 0.9327 - val_loss: 0.6922 - val_acc: 0.7434\n",
      "Epoch 15/20\n",
      "1277/1277 [==============================] - 22s 17ms/step - loss: 0.1371 - acc: 0.9475 - val_loss: 0.7728 - val_acc: 0.7124\n",
      "Epoch 16/20\n",
      "1277/1277 [==============================] - 22s 17ms/step - loss: 0.1022 - acc: 0.9624 - val_loss: 0.9183 - val_acc: 0.7257\n",
      "Epoch 17/20\n",
      "1277/1277 [==============================] - 22s 17ms/step - loss: 0.0908 - acc: 0.9655 - val_loss: 0.7317 - val_acc: 0.7168\n",
      "Epoch 18/20\n",
      "1277/1277 [==============================] - 23s 18ms/step - loss: 0.0923 - acc: 0.9687 - val_loss: 0.9403 - val_acc: 0.7035\n",
      "Epoch 19/20\n",
      "1277/1277 [==============================] - 22s 17ms/step - loss: 0.0860 - acc: 0.9655 - val_loss: 0.8295 - val_acc: 0.7212\n",
      "Epoch 20/20\n",
      "1277/1277 [==============================] - 23s 18ms/step - loss: 0.0617 - acc: 0.9804 - val_loss: 1.1434 - val_acc: 0.6858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c29f7fd5f8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading dependencies\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Activation, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "import pickle\n",
    "import cv2\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time\n",
    "\n",
    "\n",
    "NAME = \"Flower_classification-{}\".format(int(time.time()))\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
    "\n",
    "#loading data\n",
    "X = pickle.load(open(\"X.pickle\",\"rb\"))#\"rb\" represents read and binary as this is not txt\n",
    "y = pickle.load(open(\"y.pickle\",\"rb\"))\n",
    "\n",
    "\n",
    "#normalizing data\n",
    "X = X/255\n",
    "#for index,i in enumerate(X):\n",
    "#    mean = np.mean(X)\n",
    "#    (i-mean)**2\n",
    "#    if index != 0:\n",
    "#        np.sqrt(i-[index-1])\n",
    "#    else:\n",
    "#        pass\n",
    "#creating model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dropout(0.25))#used to prevent overfitting, shutsdown half the model sometimes\n",
    "model.add(Conv2D(64,(3,3),input_shape=X.shape[1:]))#(64 nodes, (3,3 convolution), input shape is X)\n",
    "model.add(Activation(\"relu\"))#gets rid of negative values\n",
    "model.add(MaxPooling2D(pool_size=(2,2))) #simplifies output\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64,(3,3),input_shape=X.shape[1:]))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "#custom optimizer\n",
    "#sgd = tf.keras.optimizers.SGD(lr=0.0001, momentum=0.0, decay=0.001, nesterov=False)\n",
    "\n",
    "#compiling model\n",
    "model.compile(loss=\"binary_crossentropy\",#this is used as the output is not binary\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#fiting input into model\n",
    "model.fit(X,y,batch_size=8, epochs=20, validation_split=0.15, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pickle.load(open(\"prediction_images/test.pickle\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(test,batch_size=1, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 9ms/step\n",
      "[[0]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict_classes(test,batch_size=1,verbose=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "`save_model` requires h5py.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-c362c89399da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"FlowerCNN.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\alex\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m   1276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msave_model\u001b[0m  \u001b[1;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m     \u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1280\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alex\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'`save_model` requires h5py.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mkeras_version\u001b[0m  \u001b[1;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: `save_model` requires h5py."
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "model.save(\"FlowerCNN.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
